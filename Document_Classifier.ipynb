{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyP7vArI61XzejrHe73hZ+yC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AyonSOMADDAR/NLP/blob/main/Document_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcRdbsJQEwd7"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "#get the gpu name\n",
        "device_name=tf.test.gpu_device_name()\n",
        "\n",
        "#the device name should look like the following\n",
        "\n",
        "if device_name=='/device:GPU:0':\n",
        "  print(f'Found GPU as: {device_name}')\n",
        "else:\n",
        "  raise SystemError('GPU device not found')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "if torch.cuda.is_available():  #if GPU is available\n",
        "  #telling pytorch to use GPU\n",
        "  device = torch.device(\"cuda\")\n",
        "  print(f\"There are {torch.cuda.device_count()} GPU's available\")\n",
        "  print(f'We will be using the GPU: {torch.cuda.get_device_name(0)}')\n",
        "else:\n",
        "  print('No GPU available, USING CPU INSTEAD......')\n",
        "  device=torch.device('CPU') # using cpu \n"
      ],
      "metadata": {
        "id": "odvhTNCTH3bJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#INSTALLING BERT\n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "zg-riF6RJXeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we are using CoLA DATASET \n",
        "!pip install wget"
      ],
      "metadata": {
        "id": "7xMwhL75KU6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wget\n",
        "import os\n",
        "\n",
        "print('Downloading dataset...')\n",
        "\n",
        "# The URL for the dataset zip file.\n",
        "url = 'https://nyu-mll.github.io/CoLA/cola_public_1.1.zip'\n",
        "\n",
        "# Download the file (if we haven't already)\n",
        "if not os.path.exists('./cola_public_1.1.zip'):\n",
        "    wget.download(url, './cola_public_1.1.zip')"
      ],
      "metadata": {
        "id": "gniV_q_JKl6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#unzipping the dataset\n",
        "if not os.path.exists('./cola_public/'):\n",
        "  !unzip cola_public_1.1.zip\n"
      ],
      "metadata": {
        "id": "vo6e0xW4KyjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv(\"/content/cola_public/raw/in_domain_train.tsv\",delimiter='\\t')\n",
        "#reporting number of sentences\n",
        "print(f'Number of training sentences: {df.shape[0]}\\n',)\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "invMbrXwLt1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sample(10)"
      ],
      "metadata": {
        "id": "pHOxzm_ANJbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.rename(columns={'1':'label'},inplace=True)\n",
        "df.rename(columns={\"Our friends won't buy this analysis, let alone the next one we propose.\":\"sentence\"},inplace=True)\n"
      ],
      "metadata": {
        "id": "2fieETRkOQDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "0JQl7j1YOpJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[df.label==0].sample(5)[['sentence','label']]"
      ],
      "metadata": {
        "id": "QHK48lSQNSUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#listing sentences and their labels\n",
        "sentences=df.sentence.values\n",
        "labels=df.label.values"
      ],
      "metadata": {
        "id": "mHhoq6ElPC1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#installing BERT tokenizer\n",
        "from transformers import BertTokenizer\n",
        "print('Loading BERT Tokenizer >>>>>')\n",
        "tokenizer=BertTokenizer.from_pretrained('bert-base-uncased',do_lower_case=True)\n"
      ],
      "metadata": {
        "id": "sIuqAiHzPjBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#applying to one sentence to get the output\n",
        "print(f'Original: {sentences[0]}')\n",
        "#print the sentence into tokens\n",
        "print(f'Tokenized: {tokenizer.tokenize(sentences[0])}')\n",
        "#print the sentence mapped to token ids.\n",
        "print(f\"Token IDs:{tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0]))}\")"
      ],
      "metadata": {
        "id": "490Zytx-QW0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#NOW WE ARE TOKENIZING ALL THE SENTENSEX AND MAPPING THEM TO WORD IDS\n",
        "input_ids=[]\n",
        "for sent in sentences:\n",
        "  encode_sent=tokenizer.encode(\n",
        "      sent,\n",
        "      add_special_tokens=True\n",
        "      #here truncation and conversion can be done, but padding cannot be done.\n",
        "      #hence we cannot use the following features:\n",
        "      #max_length=128 #for truncation\n",
        "      #return_tensors='pt',#return pytorch tensors\n",
        "  )\n",
        "  input_ids.append(encode_sent)\n",
        "\n",
        "#printing the first statement as a list of IDS. \n",
        "print(f'Original: {sentences[0]}')\n",
        "print(f'Token IDs: {input_ids[0]}')"
      ],
      "metadata": {
        "id": "NkPx78oVRXsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Maximum sentence length: {max([len(sen) for sen in input_ids])}\")"
      ],
      "metadata": {
        "id": "s_lcmycibePQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#padding and truncating the encoded sentences to the max size using Keras library\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "MAX_LEN=64\n",
        "print(f'\\nPadding/truncating all sentences to {MAX_LEN} values...' )\n",
        "print(f'\\nPadding token: \"{tokenizer.pad_token}\", ID: {tokenizer.pad_token_id}')\n",
        "input_ids=pad_sequences(input_ids,maxlen=MAX_LEN,dtype=\"long\",value=0,truncating='post',padding='post')\n",
        "print(\"done\")"
      ],
      "metadata": {
        "id": "kHylhodRdqUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CREATING ATTENTION MASKS FOR STORING THE LIST OF INDEXES\n",
        "attention_masks=[]\n",
        "for sent in input_ids:\n",
        "  att_mask=[int(token_id>0)for token_id in sent]\n",
        "  # Here in the above sentence we are checking if:\n",
        "  # token_id is 0 then false i.e we append 0. \n",
        "  # if token_id is 1 then true i.e we append 1.\n",
        "  attention_masks.append(att_mask)"
      ],
      "metadata": {
        "id": "A2G52N7YgFOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#NOW WE COME TO TRAINING AND VALIDATION \n",
        "from sklearn.model_selection import train_test_split\n",
        "#we will be using 90% of the result for validation.\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                                         random_state=2018, test_size=0.1)\n",
        "#doing the same for the masks.\n",
        "train_masks,validation_masks,_,_=train_test_split(attention_masks,labels,random_state=2018,test_size=0.1)\n"
      ],
      "metadata": {
        "id": "EqtaZvsnh7Jv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vkU3qpShilzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CONVERTING TO PYTORCH TENSORS\n",
        "train_inputs=torch.tensor(train_inputs)\n",
        "validation_inputs=torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels=torch.tensor(train_labels)\n",
        "validation_labels=torch.tensor(validation_labels)\n",
        "\n",
        "train_masks=torch.tensor(train_masks)\n",
        "validation_masks=torch.tensor(validation_masks)"
      ],
      "metadata": {
        "id": "24tKJ5Cyine3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here.\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
        "# 16 or 32.\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
      ],
      "metadata": {
        "id": "ItTdquDairTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "model=BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels=2, #number is 2 for binary classification\n",
        "    output_attentions= False,\n",
        "    output_hidden_states= False,\n",
        ")\n",
        "#Tellling pytorch to run this model over GPU\n",
        "model.cuda()"
      ],
      "metadata": {
        "id": "kI3B7t1_mAAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aioTUqHEkraA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WtPEMs0YojQe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}